{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d29f979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc85de07",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a bee or a wasp. For this, we will use the \"Bee or Wasp?\" dataset that was obtained from Kaggle and slightly rebuilt.\n",
    "- https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp\n",
    "\n",
    "You can download the dataset for this homework from here:\n",
    "- https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "\n",
    "- wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "- unzip data.zip\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch.\n",
    "\n",
    "Note: you will need an environment with a GPU for this homework. We recommend to use Saturn Cloud. You can also use a computer without a GPU (e.g. your laptop), but it will be slower.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps.\n",
    "\n",
    "The dataset contains separate folders for training and test sets.\n",
    "\n",
    "### Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "- The shape for input should be (150, 150, 3)\n",
    "- Next, create a convolutional layer (Conv2D): \n",
    "    https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "    - Use 32 filters\n",
    "    - Kernel size should be (3, 3) (that's the size of the filter)\n",
    "    - Use 'relu' as activation\n",
    "- Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "    https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "    - Set the pooling size to (2, 2)\n",
    "- Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "    https://keras.io/api/layers/reshaping_layers/flatten/\n",
    "- Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "- Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "    - The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "- As optimizer use SGD with the following parameters:\n",
    "    https://keras.io/api/optimizers/sgd/\n",
    "    - SGD(lr=0.002, momentum=0.8)\n",
    "\n",
    "For clarification about kernel size and max pooling, check Office Hours.\n",
    "https://www.youtube.com/watch?v=1WRgdBTUaAc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d6747b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "03ac666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a9139",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- mean squared error\n",
    "- binary crossentropy\n",
    "- categorical crossentropy\n",
    "- cosine similarity\n",
    "\n",
    "    Note: since we specify an activation for the output layer, we don't need to set from_logits=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "05d72b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "sgd = SGD(learning_rate=0.002, momentum=0.8)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718b6d1",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the summary method for that.\n",
    "\n",
    "- 1\n",
    "- 65\n",
    "- 896\n",
    "- 11214912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "843fb281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAACCCAYAAAA9m7/zAAAQVUlEQVR4Xu2dT4wcxRWHn68kuXkXAkhBvsRre61ESqTk4HidPYAUFBFhZMcCIeWEBAQsG5M/ikCKIDIYEYMJ5BIpigFvsC8RhyBlwQ4ciIQUBKzNKSIKBLze3EKuTlf/memqru6qnpme7an69mTPdFfV+97r31RVd7+3ZdtXd1+V0t8Xvvil8n/5NwQgAIGZJrAFkZtp/zF4CEDAQQCRI0QgAIGgCSByQbsX4yAAAUSOGIAABIImgMgF7V6MgwAEEDliAAIQCJoAIhe0ezEOAhBA5IgBCEAgaAKIXNDuxTgIQACRIwYgAIGgCSByQbsX4yAAAUSOGIAABIImgMgF7V6MgwAEEDliAAIQCJoAIhe0ezEOAhBA5IgBCEAgaAKzIXJf+5E8urwuLzz1qnzm4Y7rbn5Y7lmay468eEYe/cM7HmdZDrn+fjn14O1yQ/7Vv1+/T+798wf5/3bJ3Q+dktvknBx58ln5x2g9iHz5VrnvkMhZT9tG7YbzIBArgSBFrnBmKnbzqyOK3K3y8yeOiry8Tx77u5Y82Uvk9t19XvZfvj8RxfcbYusbcvBXB0VWHpIz79r6iDUssRsCkyOAyNWxTGZxzz14o5w99hN5Q9oLkI/ILd51QvauPy2nXvtkch6lJQhAQCMweZFTS8vFdXlzfkn2bBX5cOWMyIGDsl2uyJvPHJfVT1X/N8jykcPp9/maUs799HdSnvMoAbh9R2msG+e15eriXU8m32/JDjC+m8hMrkHktt1yWp767o1ZN2sn5Ae/f3Uw0G23vJh8VyxwS+M3jkuXqT+elwuG3cQnBCAwWQLdiNyBHYm4HZW1RSVUStxOixw6LHOrR5NlWSZwCx8MZzDpsnLX2kDEUoGT0l6asSdnfl85Pmc0ynK1VqTkb/LMsYeTWd3wLz322pc1kSu+dc3kRhnbZF1PaxCIg0A3IpffJJDBntinQ2F77+uWGYzam1qWK+lMr/zv3AmayFm+r5kVjSUkHsvV0UWuKvRxhBtWQmD6BKYvcpdvttwpzS76udVkA/7y96oiWBa5VNCWZLDSHTArL4ezD/suctnMdvpOp0cIxERg+iLnmslJda/qupuPJcvZi/ly1jKTq/FY30WuvGSPKeiwFQLTJDB9kXtNKnty6Z7afHFjwVjKJbO4R5I9vi2lmwt1e3AmuGaRyx7f2C4XKzc90nbGXK6qpeyJxbflaM0zdGMJ8DQjhL4gMOMENkHk1OMSicA8nghMfnO0cne0vCRV4rY6L/doDwObd2eTJgcP/Vq+U06qPBQ8qsiph4CfldvmisHnEWDePRXjOO6uzvilwvBnlcDkRW5WSWzCuHlObhOg02V0BBC5TXU5bzxsKn46j4IAIrfZbubd1c32AP0HTgCRC9zBmAeB2AkgcrFHAPZDIHACiFzgDsY8CMROAJGLPQKwHwKBE0DkAncw5kEgdgKIXOwRgP0QCJwAIhe4gzEPArETQORGjoD89THRk3mO3BwnQgACnRAIVuS6f2UKkWuKyO75d3I90GiABBC5AJ3aB5MQuT54gTEoAsGJnFaOsOzjUhYSlZ9uv7woZ+XOQenCjfN6QRm9xoSejinNb7c0n7VeyW5SJAAtaluog6oJPZvDz55JRaWUL5JsauPTalz49V9/fpZsdL+cHomPD39XjQ8f/3D5QsCXQHAiVxjeNJMYiFQhDmlqp51yKS+0oy7UpcvHdUEZ5LsborXnhCsEaihsbXPH6fnyqqnSqzUukqI+spKXXnT333x+nlFZ1a0dg089f3eND5d/fIOb4yAQ5EzOW+QGmYbVGSq/XVJj4tmimpgRHDXFrZtETktt3qo4djETG87a9H5cNS5KqeSLWq4ta2SYhYVSPoMaHJYLx2JfrchZ63Ho7euZoD38w7UMgQYC8c7k5l+vLzptqyNhKXvYjciJNM7knDUuHCLnPN+jNoYHn1qRswq+LuypyDX5h0saAi0IIHIVWJZKWlOdyeUiV645q+37uWpcjDCTMxg0L6/9+Iw9k0PkWlzGHNpEIFiRqy65yntpTTOFIpFlsVzM06RPbSan+tstaw1Fp5trXLhEzpwpVsPDpzaGDG6C2PnU86/ZYyztefrN5IoU+jU1OrjuIZATCFbkKnfwjLurjcshNXNLiudkf8kNhJU1WVgWOfvUq/KZuGpIVPfUpNWeXGnjvxym2mzOXeMiLe9o3ZNTjTad77FcbeRTDNroozIbVUWE8j/jB8RP5JRYJzdcdmwkxctr9lK5zCGQEAhY5GbUv8ad3swKc3Y5o7ZNeNjZXdgNe7W1CfdFc7NLAJHrm+/SWdKcPjuxCl/fBj7F8QxufLBUnSL1me0KkZuq64xSjGbf+ZKu+kBt24eJp2oUnUGg1wQQuV67h8FBAALjEkDkxiXI+RCAQK8JIHK9dg+DgwAExiWAyI1LkPMhAIFeE0Dkeu0eBgcBCIxLAJEblyDnQwACvSaAyPXaPQwOAhAYlwAiNy7ByvmW17om3gcNQgACvgQQOV9S3sdNS+QW5SsPPC83bX1b1n7xkGzIVW2EWw+9KTsXtmSfbbwi75w8KZ9728CBEAiHACI3cV9OQeR2n5C9d9woH/31Y7npO1IRua2H3pKdc4Ww5WJ45Qm58NKfJm4tDUKg7wSCFbnxaiCYWTos70hqmThUpvCiRkQhck/LleXDsmerCgHztaxqFpAPV0pZQxqjRonW3fL5yaOykYqdKXLfl4VfHpL/PfdD+edn+ezuugfkm/d+W9bLn/U9MhkfBCZEIEiRq9YwOJHUQDhj1EAQKQrD6LnP3DUI0tRJ5kv0A4cMBawQLjM/W9uaD7W+tomc+VkqcHfINUkj66/skUvv6cvaCcURzUCgtwQCFDnfGgjDGgpajQdRRW3m5YKWtFJvU+Ux27v+azn12icWx7rzyWUv4F+pSRGkZmLHJK8FNmzftq9WJ3L7/iXvrIjsSMXtY/noucdEDjwv17yByPX2SmRgnREIT+ScNQxse2alQjbXJrO05XV5IU2QWfyVz3HtublFTrWqZRqplDX09HftTO5bSQNK3A4mS1bVVrYvh8h5cuWwoAiEJ3KuylJ5Vlytmla5gpSzmpSlxoEWEn4iNzwlX96uF8vpMWdy+fL0v+WlKXtyQV20GNOOQIAi56phUBUhrzqnZg2C2oy0bUVOzepGrE5lvfEgot9dzf8v5t3VvDaDkHiy3SXD0bNGIEiRa65h0FzfIHNgIQC5O+uK2KgCzINDzLurpT0/rcaDpX9L+02BlIrYgnmEel4uueOafqyWp79JnqHLn5O7ZH98JLsDTULOWbtoGW87AoGKXBME155aO4CzfHTzDZBZtoyxQ2BIAJGLMRqokRCj16O1GZGL1vUYDoE4CEQocnE4FishAIGMACJHJEAAAkETQOSCdi/GQQACiBwxAAEIBE0AkQvavRgHAQggcsQABCAQNAFEzuJev5fn8zcX5LzxMr+lQe2Nh0nFU4v+J9VlXTud2Nf1oGk/FgKIXIOnm/O+tRCZEURAvXK1d714Vcw2yBb9dx3Nndg33qDd/MZtvynd1nhtz8LZXfOdJANEbmSRa+GGHopAi9G7D+2hfV1fhM05Bd3IZv2IrvlOkk94Ipe+srRTLj1zXFY/zVFZPtPSo9dk4qibyaVZQ5bytJY1ueD09pNxGC/h1/WvLZXLni71415ON6VvL97dPZMk0jwo29M+2r+k36V9akQ+/rFdCJpvavhl7T+ZJCcoCv2YWw629PRZwgUf/7gvUEuShuSkcgr88dL3G/yM2FOM9suLclbuTOI4SzIxTN+fjV7jU7o+/Pg2lw9QDPfL6cb+3Qz9jwhP5PJ8cQsfDJd6enrzLLXR0uUn0qAdXFClVEoFPlea8rrvzfTrabr0UiJOdd7S5eOl/pMLbv6Ctrfn80tp79+Vvr0IwKGwtU315LbPzbfJvqp/qnxcId7UfnN6/FzI5lfzdPn2nsaZyaUCIitaOv5yvPql7y/7L8k0XRqv2778R7oQP2MSUI3PJFuNcX3U83XFX+mHoqZ/l2/bfh+gyOUQd63louGRdSQRoUcSEfqtlg3YHex2kbGkX3ct5yz9jyxynkk/taShrvFpUTU9+wbdanz8korW83Olxy8uwrr09MOZTn0K/KbLsIjHYeEiPY5c47PnKxzGr+v8PH/hroulH9VSZuxi9VM2wRIftXyd8Wden6ojy5jbKlnD8UGKXAZtt6ypOg026LYU6XU54xp+0a0iZ+vPDBKP/kcWOatglS+s62X5yGEZWeSmYZ8HH9c10HwRLklaRE3705fsri2BzmZyo6TvL/8IOM/3SNLqwb+WrzP+rmZLfsdM2eXfNt8HKnLZnsTO95N9FEmWiovvlZYelvTlk5zJWUTAVQ1MLWfNmeTIIuf8JW2fuVgLqM7tc/mng5lc4xVjpqcfdyZn7ncl7Wn7uq5ZzQgzOcO+5u0JO3+z7snYMzlEro1O1xyrflEScTsnyzL/l9JNCDXLe/ygyB+LzL15FuBJzeTMPcGiPuug/aw/WSn1n4xn+3/0zW9zH9Fmpe+eXLpHM9hTGVPkfOzz4Ftvn8U/Fj6uCGniV9lTdDRmE4X0M23J5xpR8b2yL1ll/CxZZdSc0jw+l8i50v+7ZnJFfBbLafv1Uc+3KpJ6/Lm3gXxJ+h4X7ExukALd9rCuVhg6WaasrMnCssjZdE/Ofudr+Gvr+j5BX57uK3FbnZd7yhXAGvsvXGf0M/i19+g/F/Lt+c1D/c7uuCLXtX1J+158XCFex0+dZ2HYxNeanr6p/eaxWe9QarM59/jM7QZ9JdB0vkvkMv6PHNghWfiY14crPtX32Q+VPf4QOVfk8j0EZpuA7RGnwepieDNito3s1+gDnsn1CzSjgUBKIJ0lzclbjuc4oTU5Aojc5FgG0JJRpcy0aNQi2AGQ8TPBj191udr+YWy/8XCUIoDIEQcQgEDQBBC5oN2LcRCAACJHDEAAAkETQOSCdi/GQQACiBwxAAEIBE0AkQvavRgHAQggcsQABCAQNIGORE69VnKnyEvld0aD5ohxEIBATwl0JHKJten7hyLnVLqjnhrPsCAAgfAJdCdyCbtp540K311YCAEItCXQqch1nfGzrbEcDwEIxEegY5HLcls1l9aLDzoWQwAC0yPQucj5JH+cnrn0BAEIxEagc5GzpfaODTL2QgACm0egc5Hj5sPmOZeeIQCBKaRaYk+OMIMABDaTQMczOVfloc00nb4hAIEYCHQqcixVYwghbIRAvwl0J3K88dBvzzM6CERCoCOR493VSOIHMyHQewIdiVzv7WaAEIBAJAQQuUgcjZkQiJUAIher57EbApEQQOQicTRmQiBWAohcrJ7HbghEQgCRi8TRmAmBWAkgcrF6HrshEAkBRC4SR2MmBGIlgMjF6nnshkAkBBC5SByNmRCIlQAiF6vnsRsCkRBA5CJxNGZCIFYCiFysnsduCERCAJGLxNGYCYFYCSBysXoeuyEQCQFELhJHYyYEYiWAyMXqeeyGQCQEELlIHI2ZEIiVQEXkYgWB3RCAQJgEELkw/YpVEIBATgCRIxQgAIGgCfwf8XNdDqUJUEwAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "4031ab9c",
   "metadata": {},
   "source": [
    "## Generators and Training\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "   - We don't need to do any additional pre-processing for the images.\n",
    "   - When reading the data from train/test directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "   - Use batch_size=20\n",
    "   - Use shuffle=True for both training and test sets.\n",
    "\n",
    "For training use .fit() with the following params:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5a9ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a197b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory('./data/data/train',\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        shuffle=True,\n",
    "                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0f063dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./225)\n",
    "test_ds = test_gen.flow_from_directory('./data/data/test',\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        shuffle=True,\n",
    "                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4719171c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06403072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e8ba7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 25s 136ms/step - loss: 0.6807 - accuracy: 0.5572 - val_loss: 0.6377 - val_accuracy: 0.6122\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 24s 132ms/step - loss: 0.6456 - accuracy: 0.6212 - val_loss: 0.6189 - val_accuracy: 0.6394\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.5909 - accuracy: 0.6834 - val_loss: 0.6177 - val_accuracy: 0.6580\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 25s 135ms/step - loss: 0.5528 - accuracy: 0.7212 - val_loss: 0.5451 - val_accuracy: 0.7255\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 25s 133ms/step - loss: 0.5148 - accuracy: 0.7495 - val_loss: 0.5651 - val_accuracy: 0.7168\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 25s 134ms/step - loss: 0.4966 - accuracy: 0.7680 - val_loss: 0.5474 - val_accuracy: 0.7222\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 24s 131ms/step - loss: 0.4664 - accuracy: 0.7871 - val_loss: 0.5183 - val_accuracy: 0.7538\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 24s 131ms/step - loss: 0.4296 - accuracy: 0.8099 - val_loss: 0.5357 - val_accuracy: 0.7407\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 24s 130ms/step - loss: 0.4076 - accuracy: 0.8224 - val_loss: 0.5193 - val_accuracy: 0.7582\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 24s 130ms/step - loss: 0.3770 - accuracy: 0.8431 - val_loss: 0.5054 - val_accuracy: 0.7582\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c727793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbcd4f",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "    0.20\n",
    "    0.40\n",
    "    0.60\n",
    "    0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e54e1bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587707340717316"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84a4d2",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "    0.031\n",
    "    0.061\n",
    "    0.091\n",
    "    0.131\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f33d18ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09604819541004547"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ba146",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bf92c",
   "metadata": {},
   "source": [
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9705b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./225,\n",
    "                              rotation_range=50,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6f44fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory('./data/data/train',\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size=20,\n",
    "                                        shuffle=True,\n",
    "                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8b3b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 36s 197ms/step - loss: 0.4884 - accuracy: 0.7718 - val_loss: 0.4872 - val_accuracy: 0.7680\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4885 - accuracy: 0.7756 - val_loss: 0.4857 - val_accuracy: 0.7756\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4801 - accuracy: 0.7751 - val_loss: 0.4940 - val_accuracy: 0.7712\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4706 - accuracy: 0.7903 - val_loss: 0.4587 - val_accuracy: 0.7810\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4706 - accuracy: 0.7797 - val_loss: 0.4920 - val_accuracy: 0.7767\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4633 - accuracy: 0.7968 - val_loss: 0.4646 - val_accuracy: 0.8017\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 35s 192ms/step - loss: 0.4690 - accuracy: 0.7879 - val_loss: 0.4518 - val_accuracy: 0.8017\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 35s 193ms/step - loss: 0.4596 - accuracy: 0.7884 - val_loss: 0.5436 - val_accuracy: 0.7462\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 36s 193ms/step - loss: 0.4596 - accuracy: 0.7881 - val_loss: 0.4819 - val_accuracy: 0.7767\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 36s 195ms/step - loss: 0.4584 - accuracy: 0.7786 - val_loss: 0.4776 - val_accuracy: 0.7908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab176421",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "    Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "    0.18\n",
    "    0.48\n",
    "    0.78\n",
    "    0.108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b7cb0c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48369751274585726"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f86964",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "    0.38\n",
    "    0.58\n",
    "    0.78\n",
    "    0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b9144db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7834422707557678"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e6_10 = history.history['val_accuracy']\n",
    "e6_10 = e6_10[5:]\n",
    "np.mean(e6_10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
